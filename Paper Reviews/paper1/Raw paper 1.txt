Introduction:
The supply chain attacks are attacks that occur when hackers exploit vulnerabilities in libraries to infiltrate applications built on top of them. Those types of attacks have experienced a rapid growth in recent years, with reports showing 650% growth in 2021 followed by 742% growth in 2022. To mitigate the damage resulted from those attacks, engineers are creating tools that can detect vulnerabilities in libraries used in projects. However, existing tools are insufficient as they do not show how those vulnerabilities may be exploited. Moreover, those tools provide up to 99% false positive rates for vulnerabilities detected, leading to missing some actual vulnerabilities and causing frustration for the developers. Therefore, developers often tend to reject those tools. Therefore, tools are needed that actually show developers how those vulnerabilities can be exploited (proof-of-concept exploits) to convince the developers to use those tools. Current tools such as SEIGE and TRANSFER do not provide satisfying results, so this study aims to explore ChatGPT's ability to generate security tests. The study has three research questions which are:
1) How effectively does ChatGPT generate security tests?
2) How does ChatGPTâ€™s security performance differ given various types of prompts?
3) How does ChatGPT compare with existing tools of security test generation?

Methodology: 
The study goes through three main phases to test ChatGPT's ability to generate security tests. The first phase is the dataset construction. In this phase, the researchers looked for applicable projects that use Java libraries that have vulnerabilities. The libraries found were filtered based on whether they can be easily exploited or not and whether they  have simple setups that can be tested to show undesired behavior or not. After filtration of 628 vulnerabilities, the research team was left with 45 unique entries. After that, the team looked for GitHub projects that use the detected vulnerabilities in libraries. The projects selected must compile successfully and they must call the API that has the chosen vulnerability in the library. 15 of the unique entries of vulnerabilities had no applicable projects, leaving the team with 30 vulnerabilities in their dataset. The team also injected some vulnerabilities into some existing projects, which they claim did not affect the results. The dataset construction phase was complete as the researchers had 55 app and library pairs that met all their criteria.
The second phase was prompt design, to structure well the prompt that will be given by ChatGPT to check its ability to mimic the exemplar test and craft malicious inputs to the API. There were six different prompt templates that were used, with the default project template having all the prompt components generated. AFter that, the other prompts had one component missing from the prompt, which is a very clever way to identify what ChatGPT needs most to generate the needed outputs. The templates 2 to 6 were missing vulnerable APIs, the method M that calls the vulnerable API, the class defining method M, the exemplar test, and the vulnerability ID respectively. 
Finally, in stage 3 some validation was done to ensure that the tests were in the right places with careful step-by-step debugging. 

Results
ChatGPT showed impressive applicability as it generated tests for all prompts, and after some minor fixes, 40 out of the 55 pairs were compilable and runnable for the default prompt. Out of those 40 compiled tests, 24 triggered the targeted vulnerabilities as expected. The fewer the parameters used and the simpler the logic, the easier it is for ChatGPT to generate tests. Some noticeable observations within the other prompts was that the Java class defining the method M significantly reduced the performance of ChatGPT, allowing only 16 compatible tests. This suggests that ChatGPT needs a lot of context for the test generation task. Without constraining the method to be tested, the performance slightly improved. Following the same trend, removing C and the exemplar components from the prompt resulted in 1 and 0 tests that triggered the vulnerability only. This means that the domain knowledge and context are a must in those tasks. The default prompt with all components generated the best results by a considerable margin. 
Compared to the other popular tools SEIGE and TRANSFER, ChatGPT's performance was significantly better. Transfer only generated 16 applicable tests and Seige only one. Only four of Transfer's tests trigerred the needed vulnerabilities while none of Seige's tests did. Unlike the other tools and against the authors' hypothesis, ChatGPT successfully transferred the
domain knowledge and effectively produced a security test.

Discussion:
ChatGPT demonstrated exceptional applicability and ability to generate tests. ChatGPT needs the domain knowledge and context provided by the class C and the exemplar tests to function as needed. ChatGPT demonstrated great performance when asked to mimic existing tests but it was weak when it was asked to exploit vulnerabilities. Despite the insightful results, there is still a wide room for improvement as the researchers only tested on Java Libs and they did not provide parameters to ChatGPT which might result in some randomness affecting the results. However, the outstanding performance of ChatGPT compared to the existing tools shows that there is huge potential for tools that utilize LLMs to enhance the code vulnerability detection field and gain the developers validation.
